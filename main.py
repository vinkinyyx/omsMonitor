import os
import json
import io
import pandas as pd
from playwright.sync_api import sync_playwright
from datetime import datetime

def load_config() -> dict:
    conf = {}
    try:
        with open("config.json", "r", encoding="utf-8") as f:
            conf = json.load(f)
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶ config.json å¤±è´¥ (æˆ–ä¸å­˜åœ¨)ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼: {e}")

    dy_params = os.getenv("DYNAMIC_PARAMS")
    if dy_params:
        try:
            conf.update(json.loads(dy_params))
        except Exception as e:
            print(f"è§£æ DYNAMIC_PARAMS å–è¦†ç›–é…ç½®å¤±è´¥: {e}")
            
    return conf

def scrape_logs(config: dict) -> str:
    """
    ä½¿ç”¨ Playwright æŠ“å–å¼‚å¸¸æ—¥å¿—æ–‡æœ¬
    """
    print("[PROGRESS] æ­£åœ¨å¯åŠ¨æµè§ˆå™¨ç¯å¢ƒ...")
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()
        page = context.new_page()

        try:
            # 1. æ‰“å¼€ç™»å½•é¡µ
            url = config.get("url")
            if not url:
                raise ValueError("è¯·åœ¨ config.json æˆ–ç¯å¢ƒå˜é‡ä¸­é…ç½® url")
            page.goto(url, wait_until="networkidle")
            
            # 2. ç™»å½•æµç¨‹
            print("[PROGRESS] ç³»ç»Ÿç™»å½•ä¸­...")
            
            # ç­‰å¾… iframe å…ƒç´ å‡ºç°
            page.wait_for_selector("#yonbip_login_id, iframe[name='yonbip_login_id']", state="attached", timeout=30000)
            
            # è·å–å¯¹åº”çš„ frame
            login_frame = page.frame(name="yonbip_login_id")
            if not login_frame:
                raise Exception("æ— æ³•æ‰¾åˆ°åä¸º yonbip_login_id çš„ iframe")
                
            # æ£€æŸ¥æ˜¯å¦æœ‰æ™®é€šç™»å½•å¯ç‚¹å‡»
            try:
                if login_frame.locator("li#toNormalLogin").is_visible():
                    login_frame.locator("li#toNormalLogin").click()
            except Exception:
                pass
                
            username = config.get("username")
            password = config.get("password")
            
            if not username or not password:
                raise ValueError("è¯·åœ¨ config.json æˆ–ç¯å¢ƒå˜é‡ä¸­é…ç½® username å’Œ password")
            
            login_frame.locator("input#username").fill(username)
            login_frame.locator("input#password").fill(password)
            login_frame.locator("input#submit_btn_login").click()
            
            # 3. è¿›å…¥ç³»ç»Ÿä¸»é¡µå¹¶ä½¿ç”¨å…¨å±€æœç´¢
            print("[PROGRESS] ç™»å½•æˆåŠŸï¼Œæ­£åœ¨è¿›å…¥ç³»ç»Ÿä¸»é¡µ...")
            search_input = page.locator("input.searchInput--1dPNm")
            search_input.wait_for(state="visible", timeout=30000)
            
            print("[PROGRESS] æ­£åœ¨æœç´¢â€˜åç‘­æ¥å£é›†æˆæµæ—¥å¿—â€™åŠŸèƒ½...")
            search_input.click()
            search_input.fill("åç‘­æ¥å£é›†æˆæµæ—¥å¿—")
            
            page.wait_for_timeout(2000)
            page.keyboard.press("Enter")
            
            import time
            print("å¯»æ‰¾æœç´¢ç»“æœå¹¶ç‚¹å‡»...")
            clicked_result = False
            start_time = time.time()
            while time.time() - start_time < 60:
                for frame in page.frames:
                    try:
                        loc = frame.get_by_text("åç‘­æ¥å£é›†æˆæµæ—¥å¿—").last
                        if loc.is_visible():
                            loc.click()
                            clicked_result = True
                            break
                    except:
                        continue
                if clicked_result:
                    break
                page.wait_for_timeout(1000)
            
            if not clicked_result:
                raise Exception("ç­‰å¾…60ç§’ä»æ— æ³•åœ¨ä»»ä¸€ iframe ä¸­æ‰¾åˆ°æœç´¢ç»“æœæ–‡æœ¬ã€‚")

            # 4. è¿›å…¥æ—¥å¿—ç³»ç»Ÿé¡µ
            print("[PROGRESS] å·²è¿›å…¥æ—¥å¿—é¡µé¢ï¼Œæ­£åœ¨æŒ‰é…ç½®ç­›é€‰ç›®æ ‡æ•°æ®...")
            active_frame = None
            start_time = time.time()
            while time.time() - start_time < 60:
                for frame in page.frames:
                    try:
                        flow_loc = frame.locator("label[title='é›†æˆæµ'] + div input")
                        if flow_loc.count() > 0 and flow_loc.first.is_visible():
                            active_frame = frame
                            break
                    except:
                        continue
                if active_frame:
                    break
                page.wait_for_timeout(1000)
            
            if not active_frame:
                raise Exception("ç­‰å¾…60ç§’ä»æ— æ³•åœ¨ä»»ä¸€ iframe ä¸­æ‰¾åˆ°ç­›é€‰è¾“å…¥æ¡†ï¼ŒåŠ è½½è¶…æ—¶ã€‚å¯èƒ½é¡µé¢è½¬åœˆæ—¶é—´è¿‡é•¿ã€‚")
            
            # ç­‰å¾…ç¡®ä¿ä¸»æ¸²æŸ“åŒº iframe åŠ è½½å®Œæˆåçš„åŠ¨ç”»/äº‹ä»¶ç»‘å®š
            page.wait_for_timeout(3000)
            
            intercepted_data = None
            def handle_route(route, request):
                if "report/refresh" in request.url:
                    current_url = request.url
                    print(f"--- æ•æ‰åˆ°æ•°æ®è¯·æ±‚ URL: {current_url[:150]}...")
                    
                    # å°è¯•å¼ºåˆ¶æ”¹å†™åˆ†é¡µå‚æ•°
                    new_url = current_url
                    if "currPageSize=" in current_url:
                        # æ›¿æ¢ç°æœ‰çš„
                        import re
                        new_url = re.sub(r'currPageSize=\d+', 'currPageSize=1000', current_url)
                    else:
                        # è¿½åŠ æ–°çš„
                        connector = "&" if "?" in current_url else "?"
                        new_url = f"{current_url}{connector}currPageSize=1000"
                    
                    if new_url != current_url:
                        print(f"--- æ‹¦æˆªæˆåŠŸï¼šå·²å°†åˆ†é¡µè§„æ¨¡è°ƒæ•´ä¸º 1000")
                        route.continue_(url=new_url)
                    else:
                        route.continue_()
                else:
                    route.continue_()

            def handle_response(response):
                nonlocal intercepted_data
                if "report/refresh" in response.url:
                    status = response.status
                    print(f"æ”¶åˆ° API å“åº” (HTTP {status}): {response.url[:80]}...")
                    if status >= 400:
                        print(f"è­¦å‘Šï¼šAPI è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç  {status}ã€‚å¯èƒ½æ˜¯ç”±äºä¿®æ”¹ URL å‚æ•°å¯¼è‡´ç­¾åå¤±æ•ˆã€‚")
                        
                    if "application/json" in response.headers.get("content-type", ""):
                        try:
                            # åªæœ‰æˆåŠŸå“åº”æ‰å°è¯•è·å– JSON
                            if status == 200:
                                data = response.json()
                                # åªè¦åŒ…å« data å­—æ®µå°±è§†ä¸ºæ½œåœ¨æœ‰æ•ˆåŒ…
                                if "data" in data:
                                    intercepted_data = data
                                    print(f"[PROGRESS] æŠ“åŒ…éªŒè¯ï¼šæˆåŠŸæ‹¦æˆª API æ•°æ®åŒ…", flush=True)
                        except Exception as e:
                            print(f"è§£æ JSON å“åº”å‡ºé”™: {e}")
            
            page.route("**/*", handle_route)
            page.on("response", handle_response)
            
            # --- å¤„ç†â€œåˆ›å»ºæ—¶é—´â€æ—¥æœŸè¿‡æ»¤ ---
            start_date = config.get("start_date")
            end_date = config.get("end_date")
            if start_date or end_date:
                try:
                    date_inputs = active_frame.locator("label[title='åˆ›å»ºæ—¶é—´'] + div input")
                    if date_inputs.count() >= 2:
                        def set_date_robustly(input_locator, date_str, label):
                            input_locator.click()
                            page.wait_for_timeout(300)
                            # å…¨é€‰å¹¶åˆ é™¤
                            page.keyboard.press("Control+A")
                            page.wait_for_timeout(100)
                            page.keyboard.press("Backspace")
                            page.wait_for_timeout(100)
                            # é€å­—è¾“å…¥æˆ–ç›´æ¥ type (type æ¯” fill æ›´èƒ½è§¦å‘å¸ƒå‘äº‹ä»¶)
                            input_locator.type(date_str, delay=50)
                            page.wait_for_timeout(300)
                            # å…³é”®ï¼šå¿…é¡»å›è½¦ä»¥åŒæ­¥å†…éƒ¨ UI State åˆ° â€œå·²é€‰æ¡ä»¶â€
                            page.keyboard.press("Enter")
                            page.wait_for_timeout(500)
                            print(f"[PROGRESS] ç½‘é¡µéªŒè¯ï¼šå·²å¡«å†™{label}æ—¥æœŸ {date_str}", flush=True)

                        if start_date:
                            set_date_robustly(date_inputs.nth(0), start_date, "å¼€å§‹")
                        if end_date:
                            set_date_robustly(date_inputs.nth(1), end_date, "ç»“æŸ")
                except Exception as e:
                    print(f"å¤„ç†åˆ›å»ºæ—¶é—´å‡ºé”™: {e}")
            
            # --- å¤„ç†â€œé›†æˆæµâ€è¿‡æ»¤ ---
            integration_flow = config.get("integration_flow", "æ‰€æœ‰")
            try:
                flow_input = active_frame.locator("label[title='é›†æˆæµ'] + div").locator("input").first
                flow_input.click()
                page.wait_for_timeout(500)
                
                if integration_flow == "æ‰€æœ‰":
                    flow_input.fill("")
                    page.keyboard.press("Enter")
                    page.wait_for_timeout(500)
                else:
                    flow_input.fill(integration_flow)
                    page.wait_for_timeout(1000)
                    
                    # å°è¯•ç‚¹å‡»ä¸‹æ‹‰é€‰æ¡†å†…ç²¾ç¡®åŒ¹é…çš„æ–‡æœ¬
                    item_flow = active_frame.locator("li.wui-select-item").get_by_text(integration_flow, exact=True)
                    if item_flow.count() > 0 and item_flow.first.is_visible():
                        item_flow.first.click()
                    else:
                        # å…œåº•
                        page.keyboard.press("Enter")
                    page.wait_for_timeout(500)
            except Exception as e:
                print(f"å¤„ç†é›†æˆæµé…ç½®å‡ºé”™: {e}")

            # æ ¹æ®ä¼ å…¥çš„åŠ¨æ€å‚æ•°è®¾ç½®éœ€è¦æŠ“å–çš„çŠ¶æ€ï¼Œé»˜è®¤ 2ï¼ˆå…¨éƒ¨ï¼‰
            target_status = str(config.get("status", "2"))
            try:
                status_input = active_frame.locator("label[title='çŠ¶æ€'] + div").locator("input").first
                status_input.click()
                page.wait_for_timeout(500)
                
                if str(target_status) == "2":
                    status_input.fill("")
                    page.keyboard.press("Enter")
                    page.wait_for_timeout(500)
                else:
                    status_input.fill(str(target_status))
                    page.wait_for_timeout(500)
                    
                     # ç²¾ç¡®è·å–çŠ¶æ€é¡¹ï¼ˆç”±äºå¯èƒ½æœ‰0, 1ï¼‰é¿å…é€‰æ‹©é”™è¯¯
                    item_st = active_frame.locator("li.wui-select-item").get_by_text(str(target_status), exact=True)
                    if item_st.count() > 0 and item_st.first.is_visible():
                        item_st.first.click()
                    else:
                        # å¯¹äºéƒ¨åˆ†ä½äºçˆ¶çº§bodyçš„ä¸‹æ‹‰æ¡†çš„ç‰¹æ®Šå…¼å®¹
                        item_st2 = page.locator("li.wui-select-item").get_by_text(str(target_status), exact=True)
                        if item_st2.count() > 0 and item_st2.first.is_visible():
                            item_st2.first.click()
                        else:
                            page.keyboard.press("Enter")
                            
                    page.wait_for_timeout(500)
                    
                # åœ¨æ­£å¼ç‚¹å‡»æŸ¥è¯¢å‰ï¼Œå°è¯•ä» UI å±‚é¢ä¹Ÿæ‹‰æ»¡åˆ†é¡µï¼ˆåŒé‡ä¿é™©ï¼‰
                try:
                    # å¯»æ‰¾åˆ†é¡µä¸‹æ‹‰æ¡†ï¼ˆé€šå¸¸åœ¨è¡¨æ ¼åº•éƒ¨ï¼‰
                    pagination_selector = active_frame.locator("div.wui-select-selection").last
                    if pagination_selector.count() > 0:
                        pagination_selector.click()
                        page.wait_for_timeout(500)
                        # å°è¯•ç‚¹å‡» 1000 æˆ– 500
                        option_1000 = active_frame.locator("li.wui-select-item").get_by_text("1000", exact=True)
                        if option_1000.count() > 0:
                            option_1000.first.click()
                            print("[PROGRESS] UI éªŒè¯ï¼šå·²æ‰‹åŠ¨é€‰æ‹©â€˜1000â€™åˆ†é¡µ", flush=True)
                        else:
                            # å°è¯• 500
                            option_500 = active_frame.locator("li.wui-select-item").get_by_text("500", exact=True)
                            if option_500.count() > 0:
                                option_500.first.click()
                                print("[PROGRESS] UI éªŒè¯ï¼šå·²æ‰‹åŠ¨é€‰æ‹©â€˜500â€™åˆ†é¡µ", flush=True)
                        page.wait_for_timeout(500)
                except:
                    pass

                # åœ¨ç‚¹å‡»ä¹‹å‰é‡ç½®å†å²æ•°æ®æŠ“åŒ…ï¼ˆé¿å…è¯»å–åˆ°é¦–æ¬¡é¢„åŠ è½½åŒ…ï¼‰
                intercepted_data = None
                print("[PROGRESS] è§¦å‘åŒæ­¥ï¼Œæ­£åœ¨è¯·æ±‚åç«¯ API æ•°æ®...")
                active_frame.locator("button.button-search").click()
            except Exception as e:
                print(f"é€‰æ‹©çŠ¶æ€æˆ–æŸ¥è¯¢å‡ºé”™: {e}")
            
            # ç­‰å¾…ç½‘ç»œæ‹¦æˆªå¯¹è±¡å¡«è£…
            print("[PROGRESS] æ•°æ®ä¼ è¾“ä¸­ï¼Œæ­£åœ¨è·å–å…¨éƒ¨åˆ†é¡µç»“æœ...")
            start_wait = time.time()
            while time.time() - start_wait < 60:
                if intercepted_data is not None:
                    break
                page.wait_for_timeout(500)
                
            if intercepted_data is None:
                print("åœ¨ 60 ç§’å†…æœªè·å–åˆ° API è¿”å›ï¼æŠ“å–å¤±è´¥ã€‚æ­£åœ¨ç”Ÿæˆæˆªå›¾...")
                page.screenshot(path="error_screenshot.png", full_page=True)
                
                # å°è¯•æœ€åçš„ä¿åº•æ–¹æ¡ˆï¼šç›´æ¥æŠ“å– DOM è¡¨æ ¼
                try:
                    wt_holder = active_frame.locator("div.wtHolder")
                    if wt_holder.count() > 0 and wt_holder.first.is_visible():
                        logs_text = wt_holder.first.inner_text()
                        print(f"æˆåŠŸè¿›å…¥ä¿åº•æ–¹æ¡ˆï¼šæŠ“å–åˆ° DOM æ–‡æœ¬ (çº¦ {len(logs_text)} å­—ç¬¦)")
                        return f"FALLBACK_TEXT:{logs_text}"
                except:
                    pass
                    
                return ""
                
            return json.dumps(intercepted_data, ensure_ascii=False)
            
            # å¼ºåˆ¶ç¡¬ç­‰å¾… 8sï¼Œç¡®ä¿ç³»ç»Ÿæ¥å£è¿”å›ä¸”è¡¨æ ¼å®Œå…¨é‡ç»˜
            # å¦‚æœä¸ç­‰å¾…ï¼Œä¼šæŠ“å–åˆ°é»˜è®¤çš„â€œçŠ¶æ€ä¸º 0â€çš„æ—§æ—¥å¿—
            page.wait_for_timeout(8000)
            
            wt_holder = active_frame.locator("div.wtHolder")
            if wt_holder.count() > 0 and wt_holder.first.is_visible():
                logs_text = wt_holder.first.inner_text()
            else:
                logs_text = "æœªæ‰¾åˆ°åŒ…è£¹æ—¥å¿—çš„å®¹å™¨ wtHolderï¼Œå¯èƒ½ä»Šæ—¥æ— æ•°æ®æˆ–é¡µé¢ç»“æ„æœ‰å˜ã€‚"
            
            print(f"æŠ“å–åˆ°æ—¥å¿—å†…å®¹é•¿åº¦: {len(logs_text)}")
            return logs_text

        except Exception as e:
            try:
                page.screenshot(path="error_screenshot.png")
                with open("dom.txt", "w", encoding="utf-8") as f:
                    f.write(page.content())
                print("å·²ä¿å­˜é”™è¯¯æˆªå›¾è‡³ error_screenshot.pngï¼ŒDOM è‡³ dom.txt")
            except Exception as inner_e:
                print(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å¤±è´¥: {inner_e}")
            print(f"ç½‘é¡µæŠ“å–è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
            return f"ç½‘é¡µæŠ“å–å¤±è´¥: {e}"
            
        finally:
            browser.close()


def process_and_save_data(logs_text: str, config: dict):
    # ================= 1. æ¸…ç†æ—§æ–‡ä»¶ =================
    # æ¯æ¬¡å¼€å§‹å¤„ç†å‰ï¼Œå…ˆå¼ºåˆ¶åˆ é™¤æ—§æ–‡ä»¶ï¼Œé˜²æ­¢ç¨‹åºä¸­é€”æŠ¥é”™å¯¼è‡´å‘é€ä¸Šä¸€æ¬¡çš„â€œå¹½çµæ–‡ä»¶â€
    for old_file in ["error_logs.txt", "error_logs.xlsx", "report_summary.md"]:
        if os.path.exists(old_file):
            try:
                os.remove(old_file)
            except Exception as e:
                print(f"æ¸…ç†æ—§æ–‡ä»¶ {old_file} å¤±è´¥: {e}")

    def save_empty_result(msg):
        df_empty = pd.DataFrame([{"å·¡æ£€ç»“æœ": msg}])
        df_empty.to_csv("error_logs.txt", sep='\t', index=False, encoding='utf-8-sig')
        df_empty.to_excel("error_logs.xlsx", index=False)

        # ğŸ‘‡ è¡¥ä¸Šè¿™ä¸‰è¡Œï¼šç”Ÿæˆå…¨ç»¿è‰²çš„æˆåŠŸå¡ç‰‡æ–‡æ¡ˆ
        with open("report_summary.md", "w", encoding="utf-8") as f:
            f.write(f"ğŸ‰ **ç³»ç»Ÿè¿è¡Œå¹³ç¨³ï¼Œæœªå‘ç°å¼‚å¸¸ã€‚**\n\n*(é™„åŠ è¯´æ˜ï¼š{msg})*")

        print(f"[PROGRESS] æç¤ºï¼š{msg}ã€‚å·²ä¸ºæ‚¨ç”Ÿæˆè¯´æ˜æ–‡ä»¶ã€‚", flush=True)

    if not logs_text or logs_text.strip() == "":
        save_empty_result("æ²¡æœ‰æŠ“å–åˆ°å¼‚å¸¸æ—¥å¿—æˆ–å¯¹åº”ç»“æ„ä¸ºç©º")
        return

    # ================= 2. è¯†åˆ«æ•°æ®ç±»å‹ =================
    if logs_text.startswith("ç½‘é¡µæŠ“å–å¤±è´¥:"):
        save_empty_result(f"æµè§ˆå™¨ç«¯æ‹¦æˆªæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯, è¯¦æƒ…å‚è§æ—¥å¿—æˆªå±")
        return

    if logs_text.startswith("FALLBACK_TEXT:"):
        raw_text = logs_text.replace("FALLBACK_TEXT:", "")
        lines = [l.strip() for l in raw_text.split('\n') if l.strip()]
        if not lines:
            save_empty_result("è¿›å…¥äº†ä¿åº•æ–¹æ¡ˆï¼Œä½†é¡µé¢ä¸Šæœªæ‰¾åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
            return

        df = pd.DataFrame(lines, columns=["åŸå§‹æ•°æ®è¡Œ(ä¿åº•æ–¹æ¡ˆè¾“å‡º)"])
        df.to_csv("error_logs.txt", sep='\t', index=False, encoding='utf-8-sig')
        df.to_excel("error_logs.xlsx", index=False)
        print("[PROGRESS] âœ… æ³¨æ„ï¼šç”±äº API æ‹¦æˆªå¤±è´¥ï¼Œå½“å‰å¯¼å‡ºçš„æ˜¯é¡µé¢å¯è§éƒ¨åˆ†çš„åŸå§‹æ–‡æœ¬ï¼ˆä¿åº•æ–¹æ¡ˆï¼‰ã€‚")
        return

    print("\n=== æˆåŠŸæ‹¦æˆªåˆ° API æ•°æ®ï¼Œæ­£åœ¨æå–å¹¶å¤„ç†... ===")
    try:
        data = json.loads(logs_text)
    except Exception as e:
        save_empty_result(f"æ•°æ®è§£æå¤±è´¥ï¼Œè¿”å›çš„ä¸æ˜¯åˆæ³•çš„ JSON æ ¼å¼")
        return

    try:
        # ================= 3. è§£æ JSON æ ‘ =================
        def find_best_cells(obj):
            best_cells = []
            if isinstance(obj, dict):
                if 'cells' in obj and isinstance(obj['cells'], list):
                    if len(obj['cells']) > len(best_cells):
                        best_cells = obj['cells']
                for k, v in obj.items():
                    res = find_best_cells(v)
                    if len(res) > len(best_cells):
                        best_cells = res
            elif isinstance(obj, list):
                for item in obj:
                    res = find_best_cells(item)
                    if len(res) > len(best_cells):
                        best_cells = res
            return best_cells

        cells = find_best_cells(data)

        if not cells or len(cells) < 2:
            save_empty_result("è¿”å›çš„æ•°æ®ç»“æ„ä¸­æœªæ‰¾åˆ°å¯ç”¨çš„è¡¨æ ¼æ•°æ®æˆ–æ•°æ®ä¸ºç©º")
            return

        headers = []
        header_row = cells[0]
        for col in header_row:
            if isinstance(col, list) and len(col) > 5:
                headers.append(str(col[0]))
            elif isinstance(col, dict) and 'v' in col:
                headers.append(str(col['v']))
            else:
                headers.append(str(col))

        extracted = []
        for row in cells[1:]:
            row_data = []
            for col in row:
                if isinstance(col, list) and len(col) > 5:
                    row_data.append(str(col[0]))
                elif isinstance(col, dict) and 'v' in col:
                    row_data.append(str(col['v']))
                else:
                    if col is None:
                        row_data.append('')
                    else:
                        row_data.append(str(col))
            extracted.append(row_data)

        if not extracted:
            save_empty_result("JSON æ•°æ®æå–å®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•è¡Œçº§åŸå§‹æ—¥å¿—è®°å½•")
            return

        # ================= 4. åˆå§‹åŒ– DataFrame =================
        df = pd.DataFrame(extracted, columns=headers)
        print(f"--- è°ƒè¯•ä¿¡æ¯ï¼šåŸå§‹æŠ“å–åˆ° {len(df)} æ¡è®°å½• ---")

        # ğŸš¨ æ ¸å¿ƒä¿®å¤1ï¼šå‰”é™¤é‡å¤åˆ—åä¸åƒåœ¾åˆ—ï¼ˆè§£å†³ 'str' æŠ¥é”™é—®é¢˜ï¼‰
        df = df.loc[:, ~df.columns.duplicated()]
        df = df.loc[:, ~df.columns.isin(['', 'None', 'nan', 'NaN'])]

        # ================= 5. æ•°æ®æ·±åº¦æ¸…æ´— =================
        # ğŸš¨ æ ¸å¿ƒä¿®å¤2ï¼šé™ç»´æ‰“å‡»ï¼Œå¼ºåˆ¶å…¨è¡¨è½¬ä¸ºçº¯å­—ç¬¦ä¸²ï¼ŒæŠ¹å¹³æ•°å­—ä¸æµ®ç‚¹æ•°
        for col in df.columns:
            df[col] = df[col].fillna('').astype(str).str.strip()
            # æ¸…ç† Pandas è¯¯è®¤æ•´æ•°ä¸ºæµ®ç‚¹æ•°å¸¦å…¥çš„ .0 å°¾å·´
            if df[col].str.endswith('.0').any():
                df[col] = df[col].str.replace(r'\.0$', '', regex=True)

        # ç§»é™¤æ— ç”¨åˆ—
        cols_to_drop = [c for c in ['ä¸»é”®', 'ç¼–ç '] if c in df.columns]
        if cols_to_drop:
            df.drop(columns=cols_to_drop, inplace=True)

        # ç™½åå•è¿‡æ»¤
        whitelist = config.get("whitelist", [])
        msg_col = next((c for c in df.columns if 'æ¶ˆæ¯' in c), None)
        if whitelist and msg_col:
            pre_len = len(df)
            for w in whitelist:
                df = df[~df[msg_col].str.contains(w, na=False, regex=False)]
            dropped = pre_len - len(df)
            if dropped > 0:
                print(f"[PROGRESS] ğŸ§¹ ç™½åå•è¿‡æ»¤ï¼šå‘½ä¸­æ’é™¤è¯æ±‡ï¼Œå‰”é™¤ {dropped} æ¡ï¼Œå‰©ä½™ {len(df)} æ¡", flush=True)

        # ä¸“å±å±è”½ï¼šâ€œåå¤â€ç›¸å…³é›†æˆæµç›´æ¥å¼ºåˆ¶æŠ›å¼ƒ
        flow_col = next((c for c in df.columns if 'é›†æˆæµ' in c), None)
        if flow_col and not df.empty:
            pre_len = len(df)
            df = df[~df[flow_col].str.contains("åå¤", na=False, regex=False)]
            dropped = pre_len - len(df)
            if dropped > 0:
                print(f"[PROGRESS] ğŸ§¹ ç³»ç»Ÿè¿‡æ»¤ï¼šå¼ºåˆ¶å±è”½â€œåå¦â€ç›¸å…³æµï¼Œå‰”é™¤ {dropped} æ¡ï¼Œå‰©ä½™ {len(df)} æ¡", flush=True)

        # æ—¥æœŸåŒºé—´è¿‡æ»¤
        time_col = next((c for c in df.columns if 'åˆ›å»ºæ—¶é—´' in c), None)
        if time_col and not df.empty:
            start_date = config.get("start_date")
            end_date = config.get("end_date")
            if start_date or end_date:
                pre_len = len(df)
                df_dates = pd.to_datetime(df[time_col], errors='coerce')

                if start_date:
                    s_date = pd.to_datetime(str(start_date))
                    df = df[df_dates >= s_date]
                    df_dates = df_dates[df_dates >= s_date]

                if end_date:
                    e_date = pd.to_datetime(str(end_date)).replace(hour=23, minute=59, second=59)
                    df = df[df_dates <= e_date]
                    
                dropped = pre_len - len(df)
                if dropped > 0:
                    print(f"[PROGRESS] ğŸ§¹ æ—¥æœŸè¿‡æ»¤ï¼šå‰”é™¤è¶…å‡ºèŒƒå›´è®°å½• {dropped} æ¡ï¼Œå‰©ä½™ {len(df)} æ¡", flush=True)

        # ç¬¬ä¸€é‡å»é‡ï¼šå…¨å±€æŠ¥æ–‡å»é‡ã€‚å¿…é¡»æ”¾åœ¨å‰”é™¤çŠ¶æ€ä¹‹å‰ã€‚
        # è¿™æ ·å¦‚æœåŒä¸€æ¡æŠ¥æ–‡é‡å¤è¯·æ±‚ï¼Œä¸”æœ€åä¸€æ¬¡æ˜¯æˆåŠŸçš„(0)ï¼Œè¯¥æˆåŠŸçš„0ä¼šå­˜ç•™å¹¶å¹²æ‰å†å²çš„æŠ¥é”™(1)
        # éšåç´§è·Ÿçš„çŠ¶æ€æ¸…é“å¤«å†å»æ¸…ç†0ï¼Œå°±èƒ½æŠŠè¿™ç§â€œå·²è‡ªæ„ˆâ€çš„æŠ¥é”™æ–©è‰é™¤æ ¹ã€‚
        dup_columns = []
        for col_kw in ['é›†æˆæµ', 'è¯·æ±‚æŠ¥æ–‡']:
            found_col = next((c for c in df.columns if col_kw in c), None)
            if found_col:
                dup_columns.append(found_col)

        if dup_columns and time_col and not df.empty:
            pre_len = len(df)
            df = df.sort_values(by=dup_columns + [time_col], ascending=[True] * len(dup_columns) + [False])
            df = df.drop_duplicates(subset=dup_columns, keep='first')
            dropped = pre_len - len(df)
            print(f"[PROGRESS] ğŸ§¹ æ—¶åºå»é‡ï¼šåˆå¹¶é‡å¤é‡è¯•æŠ¥æ–‡ {dropped} æ¡ï¼Œå‰©ä½™ {len(df)} æ¡", flush=True)

        # çŠ¶æ€è¿‡æ»¤ï¼šå¼ºåˆ¶å‰”é™¤æ‰€æœ‰æˆåŠŸçš„è¯·æ±‚è®°å½• (0)ï¼Œæ— è®ºå‰ç«¯æ‹‰å–äº†ä»€ä¹ˆ
        status_col = next((c for c in df.columns if 'çŠ¶æ€' in c), None)
        if status_col and not df.empty:
            pre_len = len(df)
            # ä¿ç•™æ‰€æœ‰å»é™¤ç©ºæ ¼å != '0' å’Œ != '0.0' çš„è®°å½•ï¼Œç»å¯¹é˜²æ¼
            df = df[~df[status_col].astype(str).str.strip().isin(['0', '0.0'])]
            dropped = pre_len - len(df)
            print(f"[PROGRESS] ğŸ§¹ çŠ¶æ€æ¸…æ´—ï¼šå¼ºåˆ¶å‰”é™¤æˆåŠŸè®°å½• {dropped} æ¡ï¼Œå‰©ä½™ {len(df)} æ¡æŠ¥é”™", flush=True)

        # æ¶ˆæ¯ç›¸ä¼¼åº¦å»é‡ (ç”¨æ­£åˆ™å°†åŠ¨æ€æ•°å­—å…¨å˜ä¸º '*')
        dup_columns_msg = []
        for col_kw in ['é›†æˆæµ', 'æ¶ˆæ¯']:
            found_col = next((c for c in df.columns if col_kw in c), None)
            if found_col:
                dup_columns_msg.append(found_col)

        if dup_columns_msg and time_col and not df.empty:
            pre_len = len(df)
            df['_clean_msg'] = df[dup_columns_msg[1]].str.replace(r'\d+', '*', regex=True)
            sort_cols = [dup_columns_msg[0], '_clean_msg', time_col]
            df = df.sort_values(by=sort_cols, ascending=[True, True, False])
            df = df.drop_duplicates(subset=[dup_columns_msg[0], '_clean_msg'], keep='first')
            df.drop(columns=['_clean_msg'], inplace=True)
            dropped = pre_len - len(df)
            if dropped > 0:
                print(f"[PROGRESS] ğŸ§¹ æ©ç å»é‡ï¼šåˆå¹¶åŒç±»é¡¹å™ªéŸ³ {dropped} æ¡ï¼Œæœ€ç»ˆå‰©ä½™ {len(df)} æ¡æŠ¥é”™æ¸…å•", flush=True)

        # ================= 6. æœ€ç»ˆæ’åºä¸ä¿å­˜ =================
        if time_col and not df.empty:
            df = df.sort_values(by=time_col, ascending=False)

        if df.empty:
            save_empty_result("ç»è¿‡ç™½åå•æ¶ˆæ¯å’Œæ—¥æœŸæ·±åº¦è¿‡æ»¤åï¼Œå½“å‰æ—¶é—´æ®µå†…æ— ç¬¦åˆæ¡ä»¶çš„æŠ¥é”™")
            return

        print(f"\n[PROGRESS] âœ… è¿‡æ»¤å®Œæˆï¼æœ€ç»ˆç•™å­˜çš„æŠ¥é”™è®°å½•æ¡æ•°: {len(df)} æ¡\n", flush=True)

        # ================= 7. ç”Ÿæˆç§»åŠ¨ç«¯ç›´æ¨å¯Œæ–‡æœ¬æ‘˜è¦æˆ˜æŠ¥ =================
        try:
            flow_col = next((c for c in df.columns if 'é›†æˆæµ' in c), None)
            msg_col = next((c for c in df.columns if 'æ¶ˆæ¯' in c), None)
            time_col_final = next((c for c in df.columns if 'åˆ›å»ºæ—¶é—´' in c), None)
            
            report_lines = []
            report_lines.append("ğŸš¨ **æ—¥å¿—å·¡æ£€å¼‚å¸¸æˆ˜æŠ¥**")
            report_lines.append(f"ğŸ•’ å·¡æ£€æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append(f"ğŸ“Š æ€»è®¡æŠ“è·çœŸå®æŠ¥é”™ï¼š**{len(df)}** æ¡")
            report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            
            if flow_col and msg_col and time_col_final:
                # æŒ‰ç…§æ—¶é—´ä»æ–°åˆ°æ—§ï¼Œæœ€å¤šç›´æ¥å±•ç¤ºå‰ 10 æ¡å…·ä½“å¼‚å¸¸ç•™è§‚
                display_df = df.head(10)
                
                for idx, row in display_df.iterrows():
                    flow_name = str(row[flow_col])
                    create_time = str(row[time_col_final])
                    sample_msg = str(row[msg_col])
                    
                    # å¼ºæˆªæ–­é˜²æ­¢å†…å®¹è¿‡é•¿æ’‘çˆ†å±å¹•å¯¼è‡´æˆªæ–­é£ä¹¦ä¸å‘
                    if len(sample_msg) > 60:
                        sample_msg = sample_msg[:57] + "..."
                        
                    report_lines.append(f"ğŸ”´ **{flow_name}**")
                    report_lines.append(f"ğŸ‘‰ *æ—¶é—´*: {create_time}")
                    report_lines.append(f"â”” *æ¶ˆæ¯*: {sample_msg}")
                    report_lines.append("") # ç©ºè¡Œåˆ†éš”
                
                if len(df) > 10:
                    report_lines.append(f"...åŠå…¶ä»– {len(df)-10} æ¡éšè—æŠ˜å ã€‚")
            
            report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            report_lines.append("ğŸ’¡ *è¯¦ç»†å…¨é‡æ’æŸ¥è¯·æŸ¥æ”¶éšåçš„ Excel é™„ä»¶ã€‚*")
            
            summary_text = "\n".join(report_lines)
            with open("report_summary.md", "w", encoding="utf-8") as rf:
                rf.write(summary_text)
            
            # ä½¿ç”¨ç‰¹å®šå‰ç¼€è®©æœåŠ¡ç«¯çŸ¥é“éœ€è¦æå–æ•´æ®µä½œä¸º Markdown å‘é€
            print(f"[PROGRESS] âœ… ç”Ÿæˆç®€æŠ¥å®Œæˆï¼Œå·²å‡†å¤‡å¡ç‰‡æŠ•é€’...", flush=True)
            
        except Exception as e:
            print(f"ç”Ÿæˆæ‘˜è¦æˆ˜æŠ¥æ—¶å‡ºé”™: {e}")

        # å†™å…¥ txt æ—¶ä½¿ç”¨ utf-8-sigï¼Œé˜²æ­¢åœ¨ Windows ç³»ç»Ÿä¸­ä¹±ç 
        df.to_csv("error_logs.txt", sep='\t', index=False, encoding='utf-8-sig')
        df.to_excel("error_logs.xlsx", index=False)
        print("[PROGRESS] å·¡æ£€å¤„ç†æˆåŠŸï¼å·²ç”Ÿæˆå¹²å‡€çš„ Excel æŠ¥è¡¨...")

    except Exception as e:
        print(f"å¤„ç†æˆ–ä¿å­˜å¼‚å¸¸æ—¥å¿—æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    config_dict = load_config()
    logs = scrape_logs(config_dict)
    process_and_save_data(logs, config_dict)
